import findspark
import sys
from pyspark.sql.types import StructType,StructField
from pyspark.sql import SQLContext as sqltg
from pyspark.conf import SparkConf
!export PYSPARK_PYTHON=python3
!echo $SPARK_HOME
from pyspark.context import SparkContext

location = findspark.find()
findspark.init(location, edit_rc=True)
try:
    sc.stop()
except:
    pass

import pyodbc
conn = pyodbc.connect(DRIVER = '{ODBC Driver 17 for SQL Server}',
                      SERVER = ', 1433',
                      DATABASE = 'utd',
                      UID = 'sa',
                      PWD = '');
cursor = conn.cursor();

import tabula
from pyspark import SparkContext, SparkConf
from pyspark.sql.types import *
from pyspark.sql import SparkSession
import pandas as pd
import random
conf = SparkConf().set('spark.driver.host','127.0.0.1').setMaster("local[*]")
sc=SparkContext(conf = conf)
spark = SparkSession(sparkContext=sc)
print('worker count:', sc.defaultParallelism)


from urllib.request import Request, urlopen
import shutil
import requests
!wget -O index_2021.csv "https://s3.amazonaws.com/irs-form-990/index_2021.csv"
from pyspark.sql.functions import col, length, trim
spark.conf.set("spark.sql.pivotMaxValues", 1000000)
spark.conf.set("NotebookApp.iopub_data_rate_limit", 10000000000)
import pandas
from pyspark.sql import *
from urllib.error import HTTPError
from urllib.request import urlopen
from urllib.error import URLError
import xml.etree.ElementTree as ET
from socket import timeout
import time

headers = {'User-Agent': 'Mozilla/5.0'}


dfindex = spark.read.option("header",True) \
            .csv("index_2021.csv")


sql_clear_query = "TRUNCATE TABLE utd.dbo.ReturnLinks"
cursor.execute(sql_clear_query)
cursor.commit()
#dfpandas = dfindex.select(dfindex.TAXPAYER_NAME, dfindex.OBJECT_ID).toPandas()
sql_insert_query = 'INSERT INTO utd.dbo.ReturnLinks' + '(Name, ReturnSt) VALUES (?,?)'
    
taxname = dfindex.rdd.map(lambda x: (x.TAXPAYER_NAME, x.OBJECT_ID)).collect()
#objectid = dfindex.rdd.map(lambda x: (x.OBJECT_ID)).collect()
g = 0
row2 = []
row3 = []
i = 0
!rm -rf returndata/
!mkdir returndata
print(taxname[0])
for row in taxname:
    #cursor.execute(sql_insert_query, row)
    g += 1
    row2.append("https://s3.amazonaws.com/irs-form-990/" + str(row[1]) + "_public.xml")
    row3.append(str(row[0]))
    rowid = row[1]+"_public.xml"
    if (g % 100000 == 0):
        print("Still going, file #" + str(g))
    
    cursor.execute(sql_insert_query, str(row[0]), str(row2[i]))
    i += 1
cursor.commit()
sql_grabitem_query = 'SELECT TOP (1) [Name],[ReturnSt] FROM [utd].[dbo].[ReturnLinks]'
cursor.execute(sql_grabitem_query)

j = 0
for things in row2:
    #try:
        if j % 1000 == 0:
            print(str(j) + " files downloaded, stopping for 15 to fix webscraping")
            time.sleep(15)
        request = Request(things, headers=headers)
        response=urlopen(request)
        with open("returndata/"+ str(row3[j])+".xml", 'wb') as outfile:
            shutil.copyfileobj(response, outfile)
        file_path = "returndata/" + str(row3[j]+".xml")
        if j % 100000 == 0:
            print(str(j) + " files downloaded.")
        root = ET.parse(file_path).getroot()
    
        j += 1    
    #except ConnectionResetError:
        print("==> ConnectionResetError")
        time.sleep(10)
        pass
    #except timeout: 
        print("==> Timeout")
        time.sleep(10)
        pass
    #except HTTPError:
        print("==> HTTP Error")
        time.sleep(10)
        pass
    #except URLError:
        print("==> URL Error")
        time.sleep(10)
        pass

print(str(g) + " items added to ReturnStrings Table in UTD Database.")    
