#import findspark
#from pyspark.conf import SparkConf
#from pyspark.context import SparkContext

# Find Spark Locally
#location = findspark.find()
#findspark.init(location, edit_rc=True)

# Start a SparkContext 
#configure = SparkConf().set('spark.driver.host','127.0.0.1')
#sc = SparkContext(master = 'local', appName='desiredName', conf=configure)
#print('worker count:', sc.defaultParallelism)

import findspark
import sys
from pyspark.sql.types import StructType,StructField
from pyspark.sql import SQLContext as sqltg
from pyspark.conf import SparkConf
!export PYSPARK_PYTHON=python3
!echo $SPARK_HOME
from pyspark.context import SparkContext

location = findspark.find()
findspark.init(location, edit_rc=True)
try:
    sc.stop()
except:
    pass

import pyodbc
conn = pyodbc.connect(DRIVER = '{ODBC Driver 17 for SQL Server}',
                      SERVER = ', 1433',
                      DATABASE = '',
                      UID = '',
                      PWD = '');
cursor = conn.cursor();

import tabula
from pyspark import SparkContext, SparkConf
from pyspark.sql.types import *
from pyspark.sql import SparkSession
import pandas as pd
import random
conf = SparkConf().set('spark.driver.host','127.0.0.1').setMaster("local[*]")
sc=SparkContext(conf = conf)
spark = SparkSession(sparkContext=sc)
print('worker count:', sc.defaultParallelism)


!wget -O index_2021.csv "https://s3.amazonaws.com/irs-form-990/index_2021.csv"
from pyspark.sql.functions import col, length, trim
spark.conf.set("spark.sql.pivotMaxValues", 1000000)
spark.conf.set("NotebookApp.iopub_data_rate_limit", 10000000000)
import pandas
from pyspark.sql import *

dfindex = spark.read.option("header",True) \
            .csv("index_2021.csv")
sql_clear_query = "TRUNCATE TABLE utd.dbo.ReturnStrings"
cursor.execute(sql_clear_query)
cursor.commit()
#dfpandas = dfindex.select(dfindex.TAXPAYER_NAME, dfindex.OBJECT_ID).toPandas()
sql_insert_query = 'INSERT INTO utd.dbo.ReturnLinks' + '(Name, ReturnSt) VALUES (?,?)'
    
taxname = dfindex.rdd.map(lambda x: (x.TAXPAYER_NAME, x.OBJECT_ID)).collect()
#objectid = dfindex.rdd.map(lambda x: (x.OBJECT_ID)).collect()
g = 0
print(taxname[0])
for row in taxname:
    #cursor.execute(sqlnew_insert_query, row)
    g += 1
    row2 = "https://s3.amazonaws.com/irs-form-990/" + str(row[1]) + "_public.xml"
    cursor.execute(sqlnew_insert_query, str(row[0]), row2)
cursor.commit()
print(str(g) + " items added to ReturnStrings Table in UTD Database.")    
    #dfindex.filter(dfindex.TAXPAYER_NAME "University").select(dfindex.OBJECT_ID).show()
#dfindex.select('TAXPAYER_NAME','OBJECT_ID').where(dfindex["TAXPAYER_NAME"].equals("Wentworth Institute of Technology").show(100000)
